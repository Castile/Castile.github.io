<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>开源数据集 | Castile</title><meta name="description" content="开源数据集"><meta name="keywords" content="人工智能,数据集"><meta name="author" content="朱宏梁"><meta name="copyright" content="朱宏梁"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="开源数据集"><meta name="twitter:description" content="开源数据集"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><meta property="og:type" content="article"><meta property="og:title" content="开源数据集"><meta property="og:url" content="https://castile.github.io/2020/02/13/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86/"><meta property="og:site_name" content="Castile"><meta property="og:description" content="开源数据集"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://castile.github.io/2020/02/13/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86/"><link rel="prev" title="leetcode-21-合并两个有序的链表" href="https://castile.github.io/2020/02/16/leetcode-21-%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E7%9A%84%E9%93%BE%E8%A1%A8/"><link rel="next" title="Java中的Pair" href="https://castile.github.io/2020/02/12/Java%E4%B8%AD%E7%9A%84Pair/"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: false,
  copyright: undefined,
  ClickShowText: {"text":"富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善","fontSize":"15px"},
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="Castile" type="application/atom+xml">
</head><body><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">Castile</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 娱乐</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/books/"><i class="fa-fw fa fa-book"></i><span> 阅读</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 电影</span></a></li><li><a class="site-page" href="/Gallery/"><i class="fa-fw fa fa-picture-o"></i><span> 照片</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div></span><span class="pull_right" id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">35</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">31</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">5</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 娱乐</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/books/"><i class="fa-fw fa fa-book"></i><span> 阅读</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 电影</span></a></li><li><a class="site-page" href="/Gallery/"><i class="fa-fw fa fa-picture-o"></i><span> 照片</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#开源数据集"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">开源数据集</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Images-Analysis"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">Images Analysis</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Image-Motion-amp-Tracking"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">Image Motion &amp; Tracking</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Video-Analysis-amp-Scene-Understanding"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text">Video Analysis &amp; Scene Understanding</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#3D-Computer-Vision"><span class="toc_mobile_items-number">5.</span> <span class="toc_mobile_items-text">3D Computer Vision</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Analyzing-Humans-in-Images"><span class="toc_mobile_items-number">6.</span> <span class="toc_mobile_items-text">Analyzing Humans in Images</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Application"><span class="toc_mobile_items-number">7.</span> <span class="toc_mobile_items-text">Application</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Low-amp-Mid-Level-Vision"><span class="toc_mobile_items-number">8.</span> <span class="toc_mobile_items-text">Low- &amp; Mid-Level Vision</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Text"><span class="toc_mobile_items-number">9.</span> <span class="toc_mobile_items-text">Text</span></a></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#开源数据集"><span class="toc-number">1.</span> <span class="toc-text">开源数据集</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Images-Analysis"><span class="toc-number">2.</span> <span class="toc-text">Images Analysis</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Image-Motion-amp-Tracking"><span class="toc-number">3.</span> <span class="toc-text">Image Motion &amp; Tracking</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Video-Analysis-amp-Scene-Understanding"><span class="toc-number">4.</span> <span class="toc-text">Video Analysis &amp; Scene Understanding</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3D-Computer-Vision"><span class="toc-number">5.</span> <span class="toc-text">3D Computer Vision</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Analyzing-Humans-in-Images"><span class="toc-number">6.</span> <span class="toc-text">Analyzing Humans in Images</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Application"><span class="toc-number">7.</span> <span class="toc-text">Application</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Low-amp-Mid-Level-Vision"><span class="toc-number">8.</span> <span class="toc-text">Low- &amp; Mid-Level Vision</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Text"><span class="toc-number">9.</span> <span class="toc-text">Text</span></a></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png)"><div id="post-info"><div id="post-title"><div class="posttitle">开源数据集</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 发表于 2020-02-13<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> 更新于 2020-02-13</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a></span><div class="post-meta-wordcount"><i class="fa fa-file-word-o post-meta__icon fa-fw" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">3.6k</span><span class="post-meta__separator">|</span><i class="fa fa-clock-o post-meta__icon fa-fw" aria-hidden="true"></i><span>阅读时长: 13 分钟</span><div class="post-meta-pv-cv"><span class="post-meta__separator">|</span><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>阅读量:</span><span id="busuanzi_value_page_pv"></span></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h1 id="开源数据集"><a href="#开源数据集" class="headerlink" title="开源数据集"></a>开源数据集</h1><p>[toc]</p>
<h1 id="Images-Analysis"><a href="#Images-Analysis" class="headerlink" title="Images Analysis"></a>Images Analysis</h1><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">数据集</th>
<th style="text-align:center">介绍</th>
<th style="text-align:center">备注</th>
<th>网址</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Flickr30k</td>
<td style="text-align:center">图片描述</td>
<td style="text-align:center">31,783 images，每张图片5个语句标注</td>
<td><a href="http://web.engr.illinois.edu/~bplumme2/Flickr30kEntities/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td style="text-align:center">Microsoft COCO</td>
<td style="text-align:center">图片描述</td>
<td style="text-align:center">330,000 images,每张图片至少5个语句标注</td>
<td><a href="http://cocodataset.org/#download" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td style="text-align:center">ESP Game</td>
<td style="text-align:center">多标签定义图像</td>
<td style="text-align:center">20,770 images，268 tags，诸如bed, light man,music</td>
<td><a href="https://www.kaggle.com/c/challenges-in-representation-learning-multi-modal-learning/data" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td style="text-align:center">IAPRTC-12</td>
<td style="text-align:center">多标签定义图像</td>
<td style="text-align:center">19,452 images,291 tags</td>
<td><a href="http://www.imageclef.org/photodata" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td style="text-align:center">NUS-WIDE</td>
<td style="text-align:center">多标签定义图像</td>
<td style="text-align:center">269,648 images,several tags (2-5 on average) per image</td>
<td><a href="http://lms.comp.nus.edu.sg/research/NUS-WIDE.htm" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td style="text-align:center">CUHK-PEDES</td>
<td style="text-align:center">以文搜图</td>
<td style="text-align:center">34,054 images，每张图片2条描述</td>
<td><a href="http://cuhk-pedes.shuanglee.me/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td style="text-align:center">VRD</td>
<td style="text-align:center">视觉关系检测</td>
<td style="text-align:center">5,000 images, 100目录，37,993对关系</td>
<td><a href="https://cs.stanford.edu/people/ranjaykrishna/vrd/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td style="text-align:center">sVG</td>
<td style="text-align:center">视觉关系检测</td>
<td style="text-align:center">108,000 images, 998,000对关系</td>
<td><a href="https://drive.google.com/file/d/0B5RJWjAhdT04SXRfVHBKZ0dOTzQ/view" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td style="text-align:center">Visual Genome Dataset</td>
<td style="text-align:center">图像属性检测</td>
<td style="text-align:center">108,077 images, 5.4 M 区域块，2.8 M 属性，2.3 M 关系</td>
<td><a href="https://visualgenome.org/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td style="text-align:center">VQA</td>
<td style="text-align:center">问答系统</td>
<td style="text-align:center">1,105,904问题，11,059,040 回答</td>
<td><a href="http://www.visualqa.org/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td style="text-align:center">Visual7W</td>
<td style="text-align:center">问答系统</td>
<td style="text-align:center">327,939 问答对</td>
<td><a href="http://web.stanford.edu/~yukez/visual7w/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td style="text-align:center">TID2013</td>
<td style="text-align:center">图像质量评价</td>
<td style="text-align:center">25张参考图像，24个失真类型</td>
<td><a href="http://www.ponomarenko.info/tid2013.htm" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td style="text-align:center">CSIQ</td>
<td style="text-align:center">图像质量评价</td>
<td style="text-align:center">30张参考图像，6个失真类型</td>
<td><a href="http://vision.eng.shizuoka.ac.jp/mod/page/view.php?id=23" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td style="text-align:center">LIVE</td>
<td style="text-align:center">图像质量评价</td>
<td style="text-align:center">29张参考图像，5个失真类型</td>
<td><a href="http://live.ece.utexas.edu/research/quality/subjective.htm" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td style="text-align:center">WATERLOO</td>
<td style="text-align:center">图像质量评价</td>
<td style="text-align:center">4744张参考图像，20个失真类型</td>
<td><a href="https://ece.uwaterloo.ca/~k29ma/exploration/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td style="text-align:center">photo.net</td>
<td style="text-align:center">图像美观评价</td>
<td style="text-align:center">20,278张图像，打分[0,10]</td>
<td><a href="http://ritendra.weebly.com/aesthetics-datasets.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td style="text-align:center">DPChallenge.com</td>
<td style="text-align:center">图像美观评价</td>
<td style="text-align:center">16,509张图像，打分[0,10]</td>
<td><a href="http://ritendra.weebly.com/aesthetics-datasets.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td style="text-align:center">CUHK</td>
<td style="text-align:center">图像美观评价</td>
<td style="text-align:center">28,410张图像，只分高质量和低质量</td>
<td><a href="http://mmlab.ie.cuhk.edu.hk/archive/CUHKPQ/Dataset.htm" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td style="text-align:center">AVA</td>
<td style="text-align:center">图像美观评价</td>
<td style="text-align:center">255,500张图像，打分[0,10]</td>
<td><a href="https://github.com/mtobeiyf/ava_downloader" target="_blank" rel="noopener">链接</a></td>
</tr>
</tbody>
</table>
</div>
<p><a href="#开源数据集">top</a></p>
<h1 id="Image-Motion-amp-Tracking"><a href="#Image-Motion-amp-Tracking" class="headerlink" title="Image Motion &amp; Tracking"></a>Image Motion &amp; Tracking</h1><div class="table-container">
<table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody>
<tr>
<td>CUHK03</td>
<td>Person re-identification(人重识别)</td>
<td>image num:13164 person num:1360 camera num:10( 5 pairs)</td>
<td><a href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>CUHK02</td>
<td>Person re-identification(人重识别)</td>
<td>image num:7264 person num:1816 camera num:10( 5 pairs)</td>
<td><a href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>CUHK01</td>
<td>Person re-identification(人重识别)</td>
<td>image num:3884 person num:971 camera num: 2</td>
<td><a href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>VIPeR</td>
<td>Person re-identification(人重识别)</td>
<td>image num:1264 person num:632 camera num:2</td>
<td><a href="https://vision.soe.ucsc.edu/node/178" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>ETH1,2,3</td>
<td>Person re-identification(人重识别)</td>
<td>image num:8580 person num:83,35,28 camera num:1</td>
<td><a href="http://homepages.dcc.ufmg.br/~william/datasets.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>PRID2011</td>
<td>Person re-identification(人重识别)</td>
<td>image num:24541 person num:934 camera num:2</td>
<td><a href="https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/PRID11/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MARS</td>
<td>Person re-identification(人重识别)</td>
<td>image num:11910031 person num:1261 camera num:6</td>
<td><a href="http://www.liangzheng.com.cn/Project/project_mars.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Market1501</td>
<td>Person re-identification(人重识别)</td>
<td>image num:32217 person num:1501 camera num:6</td>
<td><a href="http://www.liangzheng.org/Project/project_reid.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Epic Fail (EF) dataset</td>
<td>Risk Assessment(风险评估)</td>
<td>video num:3000</td>
<td><a href="https://vision.soe.ucsc.edu/?q=node/178" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Street Accident (SA) dataset</td>
<td>Risk Assessment(风险评估)</td>
<td>video num:1733</td>
<td><a href="https://vision.soe.ucsc.edu/?q=node/178" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>OTB-50</td>
<td>visual tracking(跟踪)</td>
<td>video num:50</td>
<td><a href="http://www.visual-tracking.net/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>OTB-100</td>
<td>visual tracking(跟踪)</td>
<td>video num:100</td>
<td><a href="http://www.visual-tracking.net/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>VOT2015</td>
<td>visual tracking(跟踪)</td>
<td>video num:60</td>
<td><a href="http://www.votchallenge.net/vot2015/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>ALOV300</td>
<td>visual tracking(跟踪)</td>
<td>video num:314</td>
<td><a href="http://alov300pp.joomlafree.it/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MOT</td>
<td>visual tracking(跟踪)</td>
<td>video num:train:11 test:11</td>
<td><a href="https://motchallenge.net/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>THUMOS</td>
<td>Temporal action localization(动作定位)</td>
<td>video num:~3K activities class:20 instances:~3K</td>
<td><a href="http://crcv.ucf.edu/THUMOS14/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>ActivityNet</td>
<td>Temporal action localization(动作定位)</td>
<td>video num:20k activities class:200 instances:7.6K</td>
<td><a href="http://activity-net.org/challenges/2016/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Mexaction2</td>
<td>Temporal action localization(动作定位)</td>
<td>activities class:2 instances:1975</td>
<td><a href="http://mexculture.cnam.fr/xwiki/bin/view/Datasets/Mex+action+dataset" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>FlyingChairs dataset</td>
<td>optical flow(光流)</td>
<td>image pairs：22k</td>
<td><a href="https://lmb.informatik.uni-freiburg.de/resources/datasets/FlyingChairs.en.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>FlyingThings3D</td>
<td>optical flow(光流)</td>
<td>image pairs：22k</td>
<td><a href="https://lmb.informatik.uni-freiburg.de/resources/datasets/SceneFlowDatasets.en.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>KITTI benchmark suite</td>
<td>optical flow(光流)</td>
<td>image pairs：1600</td>
<td><a href="http://www.cvlibs.net/datasets/kitti/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MPI Sintel</td>
<td>optical flow(光流)</td>
<td>image pairs：1064</td>
<td><a href="http://sintel.is.tue.mpg.de/" target="_blank" rel="noopener">链接</a></td>
</tr>
</tbody>
</table>
</div>
<h1 id="Video-Analysis-amp-Scene-Understanding"><a href="#Video-Analysis-amp-Scene-Understanding" class="headerlink" title="Video Analysis &amp; Scene Understanding"></a>Video Analysis &amp; Scene Understanding</h1><div class="table-container">
<table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody>
<tr>
<td>UCF101</td>
<td>动作行为识别</td>
<td>13320 video,101类动作，主要是五大类：1)人-物交互；2)肢体运动；3)人-人交互；4)弹奏乐器；5)运动</td>
<td><a href="http://crcv.ucf.edu/data/UCF101.php" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>HMDB51</td>
<td>动作行为识别</td>
<td>7000 videos,51类，包括人脸表情动作，身体动作，人与人交互等</td>
<td><a href="http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/#Downloads" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Moments-in-Time</td>
<td>动作行为识别</td>
<td>1,000,000 videos,339类</td>
<td><a href="http://moments.csail.mit.edu/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>ActivityNet 1.3</td>
<td>动作行为识别</td>
<td>20,000 videos,200类</td>
<td><a href="http://activity-net.org/challenges/2016/guidelines.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Kinetics</td>
<td>动作行为识别</td>
<td>300,000 videos，400类</td>
<td><a href="https://deepmind.com/research/open-source/open-source-datasets/kinetics/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>AVA</td>
<td>动作行为识别</td>
<td>57,600 videos，80类</td>
<td><a href="https://research.google.com/ava/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Collective Activity Dataset</td>
<td>群体活动行为识别</td>
<td>44 videos,穿叉、行走、等待、交谈和排队 五类</td>
<td><a href="http://vhosts.eecs.umich.edu/vision//activity-dataset.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Choi’s New Dataset</td>
<td>群体活动行为识别</td>
<td>32 videos，聚会，谈话，分开，一起走，追逐和排队 六类</td>
<td>None</td>
</tr>
<tr>
<td>ActivityNet 1.3</td>
<td>检测动作事件的起始时间和终止时间</td>
<td>20,000 videos,200类动作的起始时间和终止时间</td>
<td><a href="http://activity-net.org/challenges/2016/guidelines.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>THUMOS</td>
<td>检测动作事件的起始时间和终止时间</td>
<td>15,000 videos，101类动作的起始时间和终止时间</td>
<td><a href="http://www.thumos.info/download.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MED</td>
<td>事件检测</td>
<td>32,744 videos,20个事件</td>
<td><a href="http://www-nlpir.nist.gov/projects/tv2017/data/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>EventNet</td>
<td>事件检测</td>
<td>90,000 videos，500个事件</td>
<td><a href="http://eventnet.ee.columbia.edu/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Columbia Consumer Video</td>
<td>事件检测</td>
<td>9,317 videos，20个事件</td>
<td><a href="http://www.ee.columbia.edu/ln/dvmm/CCV/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>ADE20K</td>
<td>事件检测</td>
<td>20,210 videos，900个事件</td>
<td><a href="http://sceneparsing.csail.mit.edu/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>DAVIS</td>
<td>视频主物体分割</td>
<td>50 videos，分割标注</td>
<td><a href="http://davischallenge.org/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>FBMS</td>
<td>视频主物体分割</td>
<td>59 videos，分割标注</td>
<td><a href="https://lmb.informatik.uni-freiburg.de/resources/datasets/moseg.en.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>IJB-C</td>
<td>视频人脸识别</td>
<td>11,000 videos，</td>
<td><a href="https://www.nist.gov/programs-projects/face-challenges" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>YouTube Faces</td>
<td>视频人脸识别</td>
<td>3,425 videos，1595 人</td>
<td><a href="https://www.cs.tau.ac.il/~wolf/ytfaces/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MS-Celeb-1M</td>
<td>视频人脸识别</td>
<td>1,000,000 images，21,000人</td>
<td><a href="http://www.msceleb.org/download/sampleset" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MSVD</td>
<td>视频描述</td>
<td>1,970 videos</td>
<td><a href="http://www.cs.utexas.edu/users/ml/clamp/videoDescription/YouTubeClips.tar" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MSR-VTT-10K</td>
<td>视频描述</td>
<td>10，000 videos</td>
<td><a href="http://ms-multimedia-challenge.com/2017/dataset" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MSR-VTT-10K</td>
<td>视频描述</td>
<td>无</td>
<td><a href="https://sites.google.com/site/describingmovies/lsmdc-2016/download" target="_blank" rel="noopener">链接</a></td>
</tr>
</tbody>
</table>
</div>
<p><a href="#开源数据集">top</a></p>
<h1 id="3D-Computer-Vision"><a href="#3D-Computer-Vision" class="headerlink" title="3D Computer Vision"></a>3D Computer Vision</h1><div class="table-container">
<table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody>
<tr>
<td>photoface database</td>
<td>基于光度立体视觉的二维和三维人脸识别数据库</td>
<td>总共7356张图像，包含1839个session和261个subjects</td>
<td>None</td>
</tr>
<tr>
<td>NYU Depth V2 dataset</td>
<td>关于RGBD 图像场景理解的数据库</td>
<td>提供1449张深度图片和他们的密集2d点类标注</td>
<td><a href="https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>SUN RGBD dataset</td>
<td>是上面的NYU Depth V2 dataset的超集，多了3D bounding boxes和room layouts的标注。</td>
<td>有10,000张RGB-D图片，有58,657个3D包围框和146,617 个2d包围框。</td>
<td><a href="http://rgbd.cs.princeton.edu/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>PASCAL3D+</td>
<td>新的三维物体检测和姿态估计数据集，从PASCAL VOC 演化而来，包含图像，注解，和3D CAD模型</td>
<td>总共12个类，平均每个类别有3000多个实例</td>
<td><a href="http://cvgl.stanford.edu/projects/pascal3d.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>IKEA</td>
<td>包含典型室内场景的三维模型的数据库，例如桌子椅子等</td>
<td>包含大约759张图片和219个3D模型</td>
<td><a href="http://ikea.csail.mit.edu/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>New Tsukuba Dataset</td>
<td>包含了很多立体物体对的数据库，用于立体物体匹配</td>
<td>总共1800个立体物体对，以及每立体对的立体视差图、遮挡图和不连续图</td>
<td><a href="https://cvlab-home.blogspot.jp/2012/05/h2fecha-2581457116665894170-displaynone.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Oxford RobotCar Dataset</td>
<td>关于户外自动驾驶的数据集。</td>
<td>包含在驾驶汽车过程从6个摄像头收集的2000w张图片，和当时的激光雷达，GPS和地面实况标注。</td>
<td><a href="http://robotcar-dataset.robots.ox.ac.uk/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Middlebury V3</td>
<td>包含高分辨率物体立体视差标注的数据库</td>
<td>包含33个类，没有明说每类有多少数据</td>
<td><a href="http://vision.middlebury.edu/stereo/eval3/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>ShapeNet</td>
<td>包含3D模型，和3d模型的类别标注的数据集，覆盖了常用的3D数据集PASCAL 3D+。</td>
<td>它涵盖55个常见的对象类别，有大约51,300个3D模型</td>
<td><a href="https://www.shapenet.org/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MICC dataset</td>
<td>包含了3D人脸扫描和在不同分辨率，条件和缩放级别下的几个视频序列的数据库。</td>
<td>有53个人的立体人脸数据</td>
<td><a href="https://www.micc.unifi.it/resources/datasets/florence-3d-faces/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>CMU MoCap Dataset</td>
<td>包含了3D人体关键点标注和骨架移动标注的数据集。</td>
<td>有6个类别和23个子类别，总共2605个数据。</td>
<td><a href="http://mocap.cs.cmu.edu/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>DTU dataset</td>
<td>关于3D场景的数据集。</td>
<td>有124个场景，每场景有49/64个位置的RGB图像和结构光标注。</td>
<td><a href="http://roboimagedata.compute.dtu.dk/?page_id=36" target="_blank" rel="noopener">链接</a></td>
</tr>
</tbody>
</table>
</div>
<p><a href="#开源数据集">top</a></p>
<h1 id="Analyzing-Humans-in-Images"><a href="#Analyzing-Humans-in-Images" class="headerlink" title="Analyzing Humans in Images"></a>Analyzing Humans in Images</h1><div class="table-container">
<table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody>
<tr>
<td>MSR-Action3D</td>
<td>包含深度的动作识别数据集，</td>
<td>有20个动作，总共557个序列。</td>
<td><a href="http://users.eecs.northwestern.edu/~jwa368/my_data.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Florence-3D</td>
<td>包含深度的动作识别数据集，</td>
<td>有9个动作，总共215个动作序列。</td>
<td><a href="https://www.micc.unifi.it/resources/datasets/florence-3d-actions-dataset/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Berkeley MHAD</td>
<td>包含深度的动作识别数据集，</td>
<td>有11个动作，产生660个动作序列。</td>
<td><a href="http://tele-immersion.citris-uc.org/berkeley_mhad" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Online Action Detection</td>
<td>包含深度的动作识别数据集，</td>
<td>数据集包含59个长序列，包含10种不同的日常生活行为。</td>
<td><a href="http://homes.esat.kuleuven.be/~rdegeest/OnlineActionDetection.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>ChaLearn LAP IsoGD Dataset</td>
<td>RGB-D图像的手势识别的数据集。</td>
<td>包括47933个RGB-D手势视频，有249个手势标签。Training有35878视频，Validation有5784个，test有6271个</td>
<td><a href="http://gesture.chalearn.org/2016-looking-at-people-cvpr-challenge/isogd-and-congd-datasets" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MAFA dataset</td>
<td>关于面部遮挡问题的数据集</td>
<td>有30, 811张人脸和35806张有遮挡的脸组成。</td>
<td><a href="http://www.escience.cn/people/geshiming/mafa.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MSRC-12 Kinect Gesture Dataset</td>
<td>手势识别数据集</td>
<td>有4900张图片，包含12个不同手势，</td>
<td><a href="https://www.microsoft.com/en-us/download/details.aspx?id=52283" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>2013 Chalearn Gesture Challenge dataset</td>
<td>手势识别数据集</td>
<td>有11000张图片，包含20个不同手势，</td>
<td><a href="http://gesture.chalearn.org/2013-multi-modal-challenge" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>WIDER FACE</td>
<td>人脸检测数据集</td>
<td>有 32,203 张图片，标注了393703个人脸。</td>
<td><a href="http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>FDDB</td>
<td>人脸检测数据集</td>
<td>2845张图片，标注了5171张人脸。</td>
<td><a href="http://vis-www.cs.umass.edu/fddb/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>300-VW dataset</td>
<td>面部表情数据集</td>
<td>包含114个视频和总计218,595帧。</td>
<td><a href="https://ibug.doc.ic.ac.uk/resources/300-VW/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>HMDB51</td>
<td>人类行为识别的数据集</td>
<td>包含51个动作，总共有6766个视频剪辑</td>
<td><a href="http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MPII Cooking Activities Dataset</td>
<td>人类行为识别的数据集</td>
<td>包含65个动作，有5609个视频</td>
<td><a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/human-activity-recognition/mpii-cooking-activities-dataset/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>UCF101</td>
<td>人类行为识别的数据集</td>
<td>包含101个动作，有13320个视频</td>
<td><a href="http://crcv.ucf.edu/data/UCF101.php" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>IJB-A dataset</td>
<td>包含视频和图片人脸识别的数据集</td>
<td>包含5712个图像和2085个视频</td>
<td><a href="https://www.nist.gov/programs-projects/face-challenges" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>YouTube celebrities</td>
<td>视频人脸识别的数据集</td>
<td>包含47位名人的1910个视频</td>
<td><a href="https://www.cs.tau.ac.il/~wolf/ytfaces/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>COX</td>
<td>视频人脸识别的数据集</td>
<td>包含1000个主题的4000个视频</td>
<td><a href="http://vipl.ict.ac.cn/view_database.php?id=3" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Human3.6M</td>
<td>人体姿态估计的数据集</td>
<td>360万张3D照片，11名受试者在4个视点下执行15个了不同的动作</td>
<td><a href="http://vision.imar.ro/human3.6m/description.php" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>iLIDS</td>
<td>行人重识别的数据集</td>
<td>476 张图像，包含119个人</td>
<td><a href="http://www.eecs.qmul.ac.uk/~xiatian/downloads_qmul_iLIDS-VID_ReID_dataset.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>VIPeR</td>
<td>行人重识别的数据集</td>
<td>632个行人图片对（由两个相机拍摄）</td>
<td><a href="https://iiw.kuleuven.be/onderzoek/eavise/viper/dataset" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>CUHK01</td>
<td>行人重识别的数据集</td>
<td>包含971行人, 3884张图片</td>
<td><a href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>CUHK03</td>
<td>行人重识别的数据集</td>
<td>包含1360行人, 13164张图片</td>
<td><a href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>RWTH-PHOENIX-Weather multi-signer 2014</td>
<td>手语识别的数据集</td>
<td>包含了5672个德语手语的句子，有65,227个手语姿势和799,006帧</td>
<td><a href="https://www-i6.informatik.rwth-aachen.de/~forster/database-rwth-phoenix.php" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>AFLW</td>
<td>人类面部关键点的数据集</td>
<td>总共约有25k张脸，每幅图像标注了大约21个位置。</td>
<td><a href="https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/aflw" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>CMU mocap database</td>
<td>动作识别的数据集</td>
<td>2235个数据，包含144个不同的动作。</td>
<td><a href="http://mocap.cs.cmu.edu/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Georgia Tech (GT) database</td>
<td>人脸识别数据库</td>
<td>50个人每人15张人脸。</td>
<td><a href="http://www.anefian.com/research/face_reco.htm" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>ORL</td>
<td>人脸识别数据库</td>
<td>40个人每个人10张图。</td>
<td><a href="https://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html" target="_blank" rel="noopener">链接</a></td>
</tr>
</tbody>
</table>
</div>
<p><a href="#开源数据集">top</a></p>
<h1 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h1><div class="table-container">
<table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody>
<tr>
<td>DogCentric Activity Dataset</td>
<td>第一视角的狗和人之间的相互行为的数据集（视频）</td>
<td>总共有10类，具体数据量没有明说，y是动作类别</td>
<td><a href="http://robotics.ait.kyushu-u.ac.jp/yumi/db/first_dog.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>JPL First-Person Interaction Dataset</td>
<td>第一视角观察动作的数据集</td>
<td>57个视频，8个大类，y是动作类别</td>
<td><a href="http://michaelryoo.com/jpl-interaction.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>NUS-WIDE</td>
<td>关于图像文本匹配的数据集</td>
<td>269,648个图像和对应的标签</td>
<td><a href="http://lms.comp.nus.edu.sg/research/NUS-WIDE.htm" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>LabelMe Dataset</td>
<td>关于图像文本匹配的数据集</td>
<td>3825个图像和对应标签</td>
<td><a href="http://labelme.csail.mit.edu/Release3.0/browserTools/php/dataset.php" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Pascal Dataset</td>
<td>关于图像文本匹配的数据集</td>
<td>5011张训练图像和4952张测试图像</td>
<td>)</td>
</tr>
<tr>
<td>ICDAR 2015</td>
<td>关于文本检测的数据集</td>
<td>1500张训练，1000张测试，y为四边形的四个顶点。</td>
<td><a href="http://rrc.cvc.uab.es/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>COCO-Text</td>
<td>关于文本检测的数据集</td>
<td>63686张图片，其中43686张被选为训练集，剩下的2万用于测试。</td>
<td><a href="https://vision.cornell.edu/se3/coco-text-2/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MSRA-TD500</td>
<td>关于文本检测的数据集</td>
<td>300个训练，200个测试图像</td>
<td><a href="http://www.iapr-tc11.org/mediawiki/index.php/MSRA_Text_Detection_500_Database_(MSRA-TD500" target="_blank" rel="noopener">链接</a>)</td>
</tr>
<tr>
<td>Microsoft 7-Scenes Dataset</td>
<td>室内人体运动的数据集</td>
<td>有7种不同室内环境，每包含500-1000张图像视频序列。</td>
<td><a href="https://www.microsoft.com/en-us/research/project/rgb-d-dataset-7-scenes/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Oxford RobotCar</td>
<td>户外自动驾驶数据集</td>
<td>包含图像，激光扫描结果和GPS数据。</td>
<td><a href="http://robotcar-dataset.robots.ox.ac.uk/" target="_blank" rel="noopener">链接</a></td>
</tr>
</tbody>
</table>
</div>
<p><a href="#开源数据集">top</a></p>
<h1 id="Low-amp-Mid-Level-Vision"><a href="#Low-amp-Mid-Level-Vision" class="headerlink" title="Low- &amp; Mid-Level Vision"></a>Low- &amp; Mid-Level Vision</h1><div class="table-container">
<table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody>
<tr>
<td>Deep Video Deblurring for Hand-held Cameras</td>
<td>video/image deblurring(图像去模糊)</td>
<td>video num:71 video time: 3-5s blurry and sharp pair image num:6708</td>
<td><a href="https://www.cs.ubc.ca/labs/imager/tr/2017/DeepVideoDeblurring/#dataset" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>GOPRO dataset</td>
<td>video/image deblurring(图像去模糊)</td>
<td>blurry and sharp pair image num:3214 train num:2103 test num:1111</td>
<td><a href="https://github.com/SeungjunNah/DeepDeblur_release" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>BSD68</td>
<td>image restoration(图像修复)/高斯降噪</td>
<td>image num:68</td>
<td><a href="https://www.robots.ox.ac.uk/~vgg/data/dtd/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>BSD100</td>
<td>“image restoration(图像修复)super resolution超分辨率重建”</td>
<td>image num:100</td>
<td><a href="https://github.com/jbhuang0604/SelfExSR/tree/master/data" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Set5</td>
<td>“image restoration(图像修复)super resolution超分辨率重建”</td>
<td>image num:5</td>
<td><a href="https://github.com/jbhuang0604/SelfExSR/tree/master/data" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Set14</td>
<td>“image restoration(图像修复)super resolution超分辨率重建”</td>
<td>image num:14</td>
<td><a href="https://github.com/jbhuang0604/SelfExSR/tree/master/data" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Urban100</td>
<td>“image restoration(图像修复)super resolution超分辨率重建”</td>
<td>image num:100</td>
<td><a href="https://github.com/jbhuang0604/SelfExSR/tree/master/data" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>NYU v2 dataset</td>
<td>“image restoration(图像修复)depth super resolution深度超分辨率重建”</td>
<td>image num:1449</td>
<td><a href="https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Middlebury dataset</td>
<td>“image restoration(图像修复)depth super resolution深度超分辨率重建”</td>
<td>image pair num: 33</td>
<td><a href="http://vision.middlebury.edu/stereo/data/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>alpha matting benchmark</td>
<td>Natural image matting(抠图)</td>
<td>“train num:27,test num:8”</td>
<td><a href="http://www.alphamatting.com/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>real image benchmark</td>
<td>Natural image matting(抠图)</td>
<td>“train num:49300,test num:1000”</td>
<td><a href="https://sites.google.com/view/deepimagematting" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>MSRA10K/MSRA-B</td>
<td>Image saliency detection(显著性区域检测)</td>
<td>image num(MSRA10K):10000 image num(MSRA-B):5000</td>
<td><a href="https://mmcheng.net/zh/msra10k/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>ECSSD</td>
<td>Image saliency detection(显著性区域检测)</td>
<td>image num:1000</td>
<td><a href="http://www.cse.cuhk.edu.hk/leojia/projects/hsaliency/dataset.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>DUT-OMRON</td>
<td>Image saliency detection(显著性区域检测)</td>
<td>image num:5168</td>
<td><a href="http://saliencydetection.net/dut-omron/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>PASCAL-S</td>
<td>Image saliency detection(显著性区域检测)</td>
<td>image num:850</td>
<td><a href="http://cbi.gatech.edu/salobj/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>HKU-IS</td>
<td>Image saliency detection(显著性区域检测)</td>
<td>image num:4447</td>
<td><a href="http://i.cs.hku.hk/~gbli/deep_saliency.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>SOD</td>
<td>Image saliency detection(显著性区域检测)</td>
<td>image num:300</td>
<td><a href="http://i.cs.hku.hk/~gbli/deep_saliency.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Describable Textures Dataset</td>
<td>texture synthesis(纹理合成)</td>
<td>image num:5640 category num:47 split train:val:test = 1:1:1</td>
<td><a href="https://www.robots.ox.ac.uk/~vgg/data/dtd/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>CVPPP leaf segmentation</td>
<td>Instance segmentation(样例分割)</td>
<td>image num: 161 train num: 128 test num: 33</td>
<td><a href="https://www.plant-phenotyping.org/CVPPP2014-dataset" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>KITTI car segmentation</td>
<td>Instance segmentation(样例分割)</td>
<td>image num: 3976 train num: 3712 test num: 144 val:120</td>
<td><a href="http://www.cvlibs.net/datasets/kitti/eval_semantics.php" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Cityscapes</td>
<td>Instance segmentation(样例分割)</td>
<td>image num: 5000 train num: 2975 test num: 1525 val:500</td>
<td><a href="https://www.cityscapes-dataset.com/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>SYMMAX</td>
<td>Symmetry Detection(对称性检测)</td>
<td>image num: train:200 test:100</td>
<td><a href="https://github.com/KevinKecc/SRN" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>WHSYMMAX</td>
<td>Symmetry Detection(对称性检测)</td>
<td>image num: train:228 test:100 object num: 1</td>
<td><a href="https://github.com/KevinKecc/SRN" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>SK506</td>
<td>Symmetry Detection(对称性检测)</td>
<td>image num: train:300 test:206 object num: 16</td>
<td><a href="https://github.com/KevinKecc/SRN" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Sym-PASCAL</td>
<td>Symmetry Detection(对称性检测)</td>
<td>image num: train:648 test:787 object num: 14</td>
<td><a href="https://github.com/KevinKecc/SRN" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Color Checker Dataset</td>
<td>Color constancy(颜色恒定)</td>
<td>image num: 568</td>
<td><a href="http://www.eecs.harvard.edu/~ayanc/oldcc/dbs.html" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>NUS 8-Camera Dataset</td>
<td>Color constancy(颜色恒定)</td>
<td>image num: 1736</td>
<td><a href="http://www.comp.nus.edu.sg/~whitebal/illuminant/illuminant.html" target="_blank" rel="noopener">链接</a></td>
</tr>
</tbody>
</table>
</div>
<p><a href="#开源数据集">top</a></p>
<h1 id="Text"><a href="#Text" class="headerlink" title="Text"></a>Text</h1><div class="table-container">
<table>
<thead>
<tr>
<th>数据集</th>
<th>介绍</th>
<th>备注</th>
<th>网址</th>
</tr>
</thead>
<tbody>
<tr>
<td>Stanford Sentiment Treebank</td>
<td>文本情感分析</td>
<td>11855个句子划分为239231个短语，每个短语有个概率值，越小越负面，越大越正面</td>
<td><a href="https://nlp.stanford.edu/sentiment/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>IMDB</td>
<td>文本情感分析</td>
<td>100,000句子，正面负面两类</td>
<td><a href="http://ai.stanford.edu/~amaas/data/sentiment/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Yelp</td>
<td>文本情感分析</td>
<td>无</td>
<td><a href="https://www.yelp.com/dataset/challenge" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Multi-Domain Sentiment Dataset(Amazon product)</td>
<td>文本情感分析</td>
<td>100,000+句子，正面负面2类或强正面、弱正面、中立、弱负面、强负面5类</td>
<td><a href="http://www.cs.jhu.edu/~mdredze/datasets/sentiment/" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>SemEval</td>
<td>文本情感分析</td>
<td>20,632句子，三类（正面、负面、中立）</td>
<td><a href="http://alt.qcri.org/semeval2017/task4/index.php?id=data-and-tools" target="_blank" rel="noopener">链接</a></td>
</tr>
<tr>
<td>Sentiment140(STS)</td>
<td>文本情感分析</td>
<td>1,600,000句子,三类（正面、负面、中立）</td>
<td><a href="https://drive.google.com/uc?id=0B04GJPshIjmPRnZManQwWEdTZjg&amp;export=download" target="_blank" rel="noopener">链接</a></td>
</tr>
</tbody>
</table>
</div>
<p><a href="#开源数据集">top</a></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">朱宏梁</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://castile.github.io/2020/02/13/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86/">https://castile.github.io/2020/02/13/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://Castile.github.io">Castile</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能    </a><a class="post-meta__tags" href="/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/">数据集    </a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/wechat.png" alt="微信"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/alipay.jpg" alt="支付宝"><div class="post-qr-code__desc">支付宝</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/02/16/leetcode-21-%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E7%9A%84%E9%93%BE%E8%A1%A8/"><img class="prev_cover lazyload" data-src="/img/cover/mergeList.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>leetcode-21-合并两个有序的链表</span></div></a></div><div class="next-post pull_right"><a href="/2020/02/12/Java%E4%B8%AD%E7%9A%84Pair/"><img class="next_cover lazyload" data-src="/img/cover/java1.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>Java中的Pair</span></div></a></div></nav><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '1a98a067225d26dccaeb',
  clientSecret: 'ded51ee8abb6454d29fa5eeb07b88441246e4971',
  repo: 'Castile.github.io',
  owner: 'Castile',
  admin: 'castile',
  id: md5(decodeURI(location.pathname)),
  language: 'zh-CN',
  updateCountCallback: commentCount
})
gitalk.render('gitalk-container')

function commentCount(n){
  document.getElementsByClassName('gitalk-comment-count')[0].innerHTML= n
}</script></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By 朱宏梁</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/av-min.js"></script><script src="/js/valine.min.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script id="canvas_nest" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/canvas-nest.js"></script><script src="https://cdn.jsdelivr.net/npm/activate-power-mode/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true; 
document.body.addEventListener('input', POWERMODE);
</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><script src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/ClickShowText.js"></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>